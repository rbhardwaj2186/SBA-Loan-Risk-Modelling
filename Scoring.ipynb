{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target encoder mapping:\n",
      "['City', 'State', 'Bank', 'BankState', 'RevLineCr', 'LowDoc', 'NewExist']\n",
      "Columns to train:\n",
      "['City_trg', 'State_trg', 'Bank_trg', 'BankState_trg', 'RevLineCr_trg', 'LowDoc_trg', 'NewExist_trg', 'NAICS', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode', 'UrbanRural', 'DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv', 'Log_DisbursementGross', 'Log_GrAppv', 'Log_SBA_Appv', 'Log_BalanceGross', 'TotalJobs', 'IncomeToLoanRatio', 'EmployeesToLoanRatio', 'JobPerLoan', 'Gauren_SBA_Appv']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def load_and_print_artifacts_dict(path):\n",
    "    artifacts_dict = pickle.load(open(path, \"rb\"))\n",
    "\n",
    "    print(\"Target encoder mapping:\")\n",
    "    print([ac for ac in artifacts_dict[\"target_encoder\"].mapping])\n",
    "\n",
    "    print(\"Columns to train:\")\n",
    "    print([ac for ac in artifacts_dict[\"columns_to_train\"]])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_and_print_artifacts_dict(\"./Artifacts/artifacts_dict_file.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(data):\n",
    "    \"\"\"\n",
    "    Function to score input dataset.\n",
    "    \n",
    "    Input: dataset in Pandas DataFrame format\n",
    "    Output: Python list of labels in the same order as input records\n",
    "    \n",
    "    Flow:\n",
    "        - Load artifacts\n",
    "        - Transform dataset\n",
    "        - Score dataset\n",
    "        - Return labels\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if \"index\" in data.columns:\n",
    "        data.drop(columns=\"index\", inplace=True)\n",
    "    #Load Artifacts\n",
    "    artifacts_dict_file = open(\"./Artifacts/artifacts_dict_file.pkl\", \"rb\")\n",
    "    artifacts_dict = pickle.load(file=artifacts_dict_file)\n",
    "    artifacts_dict_file.close()\n",
    "    \n",
    "\n",
    "    clf = artifacts_dict[\"model\"]\n",
    "    te = artifacts_dict[\"target_encoder\"]\n",
    "    te_columns = artifacts_dict[\"te_columns\"]\n",
    "    columns_to_score = artifacts_dict[\"columns_to_train\"]\n",
    "    threshold = artifacts_dict[\"threshold\"]\n",
    "    category_cols = artifacts_dict[\"category_cols\"]\n",
    "    numerical_columns = artifacts_dict[\"numerical_columns\"]\n",
    "    scaler = artifacts_dict[\"scaler\"]\n",
    "\n",
    "     # Replacing the missing values\n",
    "    for i in data['RevLineCr']:\n",
    "        if i not in ['Y','N']:\n",
    "            data['RevLineCr'].replace(i,'N',inplace=True)\n",
    "\n",
    "    for i in data['LowDoc']:\n",
    "        if i not in ['Y','N']:\n",
    "            data['LowDoc'].replace(i,'N',inplace=True)\n",
    "\n",
    "    for i in data['NewExist']:\n",
    "        if i not in [1,2]:\n",
    "            data['NewExist'].replace(i,None,inplace=True)\n",
    "\n",
    "    for column in category_cols:\n",
    "        data[column]=data[column].fillna(data[column].mode()[0])\n",
    "\n",
    "    \n",
    "    # 10 New Feature Extractions\n",
    "    import numpy as np\n",
    "    # Apply the log transformation to the specific feature in your training data\n",
    "    small_constant = 1e-10  # You can adjust this constant as needed\n",
    "    # df['LogColumn'] = np.log(df['OriginalColumn'] + small_constant)\n",
    "    data['Log_DisbursementGross'] = np.log1p(data['DisbursementGross'])\n",
    "    data['Log_GrAppv'] = np.log1p(data['GrAppv'])\n",
    "    data['Log_SBA_Appv'] = np.log1p(data['SBA_Appv'])\n",
    "    data['Log_BalanceGross'] = np.log1p(data['BalanceGross'])\n",
    "    data['TotalJobs'] = data['CreateJob'] + data['RetainedJob']\n",
    "    #train_encoded['Loan_Efficiency'] = train_encoded['DisbursementGross'] / (train_encoded['CreateJob'] + train_encoded['RetainedJob'] + 1)\n",
    "    # Calculate 'LoanToIncomeRatio' as a ratio of 'SBA_Appv' to 'DisbursementGross'\n",
    "    data['IncomeToLoanRatio'] = data['DisbursementGross'] / data['SBA_Appv']\n",
    "    # Calculate 'LoanToEmployeesRatio' as a ratio of 'SBA_Appv' to 'NoEmp'\n",
    "    data['EmployeesToLoanRatio'] = data['NoEmp'] / data['SBA_Appv']\n",
    "    # Create a binary feature to indicate loans with a balance ('BalanceGross' > 0)\n",
    "    #train_encoded['HasBalance'] = (train_encoded['BalanceGross'] > 0).astype(int)\n",
    "    # Calculate 'LoanPerJob' as a ratio of 'SBA_Appv' to 'TotalJobs'\n",
    "    data['JobPerLoan'] = data['TotalJobs'] / data['SBA_Appv'] \n",
    "    # Calculate SBA's Gaurenteed Portion of Approved Loan\n",
    "    data['Gauren_SBA_Appv'] = data['GrAppv'] / data['SBA_Appv']\n",
    "\n",
    "\n",
    "    # Scaling the numerical columns\n",
    "    data[numerical_columns] = scaler.transform(data[numerical_columns])                             \n",
    "    \n",
    "    # Target encoding the categorical columns\n",
    "    data_encoded = te.transform(data[te_columns])\n",
    "    data_encoded = data_encoded.add_suffix('_trg')\n",
    "    data_encoded = pd.concat([data_encoded, data], axis=1)\n",
    "    \n",
    "    # Renaming the columns\n",
    "    \n",
    "    for column in te_columns:\n",
    "        data_encoded[column + \"_trg\"].fillna(data_encoded[column + \"_trg\"].mean(), inplace=True)\n",
    "    \n",
    "    # Predicting the probabilities\n",
    "    y_prob = clf.predict_proba(data_encoded[columns_to_score])\n",
    "    y_pred = (y_prob[:,0] < threshold).astype(int)\n",
    "    d = {\n",
    "        \"index\": data.index,\n",
    "        \"label\": y_pred,\n",
    "        \"probability_0\": y_prob[:,0],\n",
    "        \"probability_1\": y_prob[:,1],\n",
    "        \"threshold\":threshold\n",
    "    }\n",
    "    #print(y_prob)\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ef = pd.read_csv(filepath_or_buffer=\"D:/Work/Gre/UTD/Courses/Fall/MIS6341/Softwares/Python/ml-fall-2023/Project1/SBA_loans_project_1_holdout_students_valid.csv\", sep=\",\", header='infer')\n",
    "ef1 = ef.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index  label  probability_0  probability_1  threshold\n",
      "0          0      0       0.852914       0.147086   0.505051\n",
      "1          1      0       0.736220       0.263780   0.505051\n",
      "2          2      0       0.785097       0.214903   0.505051\n",
      "3          3      0       0.736333       0.263667   0.505051\n",
      "4          4      0       0.878069       0.121931   0.505051\n",
      "...      ...    ...            ...            ...        ...\n",
      "89912  89912      1       0.500004       0.499996   0.505051\n",
      "89913  89913      0       0.850401       0.149599   0.505051\n",
      "89914  89914      0       0.641032       0.358968   0.505051\n",
      "89915  89915      0       0.567922       0.432078   0.505051\n",
      "89916  89916      0       0.789032       0.210968   0.505051\n",
      "\n",
      "[89917 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(scoring(ef1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-fall-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
